{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "test_train_splits = [{\"train\": 0, \"test\": 0} for _ in range(5)]\n",
    "\n",
    "for file in glob(\"../data/test_train_split/*.feather\"):\n",
    "    file_name = re.split(\"\\\\\\\\|/\", file)[-1]\n",
    "    test_train, split = file_name.split(\".\")[0].split(\"_\")\n",
    "\n",
    "    test_train_splits[int(split)][test_train] = pd.read_feather(file)\n",
    "\n",
    "# FIXME: For the sake of this example, we feature engineer a trend (This should really be done in test_train)\n",
    "MIN_DATE = test_train_splits[0][\"train\"][\"Date\"].min()\n",
    "MAX_DATE = test_train_splits[-1][\"train\"][\"Date\"].max()\n",
    "for i in range(len(test_train_splits)):\n",
    "    test_train_splits[i][\"train\"][\"trend\"] = (test_train_splits[i][\"train\"][\"Date\"] - MIN_DATE).dt.days / (MAX_DATE - MIN_DATE).days\n",
    "    test_train_splits[i][\"test\"][\"trend\"] = (test_train_splits[i][\"test\"][\"Date\"] - MIN_DATE).dt.days / (MAX_DATE - MIN_DATE).days\n",
    "\n",
    "test_train_splits[-1][\"train\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "SCALER_VARIABLES = [\"volume weighted price\", \"cloud_cover\", \"sunshine\", \"global_radiation\", \"max_temp\", \"mean_temp\", \"min_temp\", \"precipitation\", \"pressure\", \"snow_depth\", \"days_elapsed\", \"weekday sin\", \"weekday cos\", \"month sin\", \"month cos\", \"Time of Year sin\", \"Time of Year cos\", \"trend\"]\n",
    "DROP_VARIABLES = [\"year\", \"Date\"]\n",
    "OUTPUT_VARIABLE = \"avgKWH\"\n",
    "\n",
    "def do_transform(test_train_split, columns):\n",
    "    train_df = test_train_split[\"train\"].copy()\n",
    "    train_df = train_df.drop(DROP_VARIABLES, axis=1)\n",
    "    test_df = test_train_split[\"test\"].copy()\n",
    "    test_df = test_df.drop(DROP_VARIABLES, axis=1)\n",
    "\n",
    "    scaler_encoders = []\n",
    "    for scaler in SCALER_VARIABLES:\n",
    "        encoder = StandardScaler()\n",
    "        encoder.fit(train_df[scaler].values[:,np.newaxis])\n",
    "        train_df[scaler] = encoder.transform(train_df[scaler].values[:,np.newaxis])\n",
    "        test_df[scaler] = encoder.transform(test_df[scaler].values[:,np.newaxis])\n",
    "        scaler_encoders.append(encoder)\n",
    "\n",
    "    output_encoder = StandardScaler()\n",
    "    output_encoder.fit(train_df[OUTPUT_VARIABLE].values[:, np.newaxis])\n",
    "    train_df[OUTPUT_VARIABLE] = output_encoder.transform(train_df[OUTPUT_VARIABLE].values[:,np.newaxis])\n",
    "    test_df[OUTPUT_VARIABLE] = output_encoder.transform(test_df[OUTPUT_VARIABLE].values[:,np.newaxis])\n",
    "\n",
    "    train_x_df = train_df.drop(OUTPUT_VARIABLE, axis=1)\n",
    "    # Only keep the columsn we want\n",
    "    if columns is not None:\n",
    "        train_x_df = train_x_df[columns]\n",
    "\n",
    "    test_train_split[\"train_x\"] = train_x_df.to_numpy()\n",
    "    test_train_split[\"train_y\"] = train_df[OUTPUT_VARIABLE].to_numpy()\n",
    "    \n",
    "    test_x_df = test_df.drop(OUTPUT_VARIABLE, axis=1)\n",
    "    # Only keep the columsn we want\n",
    "    if columns is not None:\n",
    "        test_x_df = test_x_df[columns]\n",
    "\n",
    "    test_train_split[\"test_x\"] = test_x_df.to_numpy()\n",
    "    test_train_split[\"test_y\"] = test_df[OUTPUT_VARIABLE].to_numpy()\n",
    "\n",
    "    test_train_split[\"input_encoders\"] = scaler_encoders\n",
    "    test_train_split[\"output_encoder\"] = output_encoder\n",
    "\n",
    "    return test_train_split\n",
    "\n",
    "def get_test_train_splits_transformed(original_test_train_splits, columns=None):\n",
    "    original_test_train_splits = deepcopy(original_test_train_splits)\n",
    "    for i in range(len(original_test_train_splits)):\n",
    "        original_test_train_splits[i] = do_transform(original_test_train_splits[i], columns=columns)\n",
    "        # print(f\"Train {i} Shape: {original_test_train_splits[i]['train_x'].shape}\")\n",
    "        # print(f\"Test  {i} Shape: {original_test_train_splits[i]['test_x'].shape}\")\n",
    "\n",
    "    return original_test_train_splits\n",
    "\n",
    "transformed_test_train_splits = get_test_train_splits_transformed(test_train_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_cross_validation(model, test_train_splits):\n",
    "    rmses = []\n",
    "    mapes = []\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "\n",
    "    for i in range(len(test_train_splits)):\n",
    "        test_train_split = test_train_splits[i]\n",
    "        model.fit(test_train_split[\"train_x\"], test_train_split[\"train_y\"])\n",
    "        y_pred = model.predict(test_train_split[\"test_x\"])\n",
    "        y_pred = test_train_split[\"output_encoder\"].inverse_transform(y_pred[:,np.newaxis])[:,0]\n",
    "\n",
    "        y_true = test_train_split[\"test\"][OUTPUT_VARIABLE].values\n",
    "        \n",
    "        rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "        mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "        rmses.append(rmse)\n",
    "        mapes.append(mape)\n",
    "\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    return rmses, mapes, y_trues, y_preds\n",
    "\n",
    "\n",
    "rmses, mapes, y_trues, y_preds = evaluate_cross_validation(Ridge(), transformed_test_train_splits)\n",
    "print(f\"Avg RMSE: {sum(rmses) / len(rmses):0.5f}\")\n",
    "print(f\"Avg MAPE: {100 * sum(mapes) / len(mapes):0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_best_models(model, test_train_splits, model_name):\n",
    "    model.fit(test_train_splits[-1][\"train_x\"], test_train_splits[-1][\"train_y\"])\n",
    "\n",
    "    y_pred = model.predict(test_train_splits[-1][\"test_x\"])\n",
    "    y_pred = test_train_splits[-1][\"output_encoder\"].inverse_transform(y_pred[:,np.newaxis])\n",
    "\n",
    "    # Plot last test_train_split\n",
    "    plt.plot(test_train_splits[-1][\"train\"][\"Date\"].values, test_train_splits[-1][\"train\"][\"avgKWH\"].values) # Plot the train\n",
    "    plt.plot(test_train_splits[-1][\"test\"][\"Date\"].values, y_trues[-1], c=\"tab:blue\", label=\"Actual\")\n",
    "    plt.plot(test_train_splits[-1][\"test\"][\"Date\"].values, y_pred, c=\"#FF0000\", label=\"Predicted\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f\"Actual vs Predicted {model_name}\")\n",
    "\n",
    "    # TODO: add residual plots here as needed\n",
    "\n",
    "plot_best_models(Ridge(), transformed_test_train_splits, model_name=\"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "# Get test train split with only trend\n",
    "baseline_test_train_splits = get_test_train_splits_transformed(test_train_splits, columns=[\"trend\"])\n",
    "# Train model\n",
    "rmses, mapes, y_trues, y_preds = evaluate_cross_validation(Ridge(), transformed_test_train_splits)\n",
    "# Plot results\n",
    "plot_best_models(Ridge(), baseline_test_train_splits, \"Base Model\")\n",
    "print(f\"RMSE: {sum(rmses) / len(rmses):0.2f} MAPE: {sum(mapes) / len(mapes):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test train split for all the data (Used for the remainder of the notebook)\n",
    "all_data_test_train_splits = get_test_train_splits_transformed(test_train_splits, columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from random import choice\n",
    "\n",
    "RANDOM_SAMPLES = 30\n",
    "tests = {} # (alpha) => (avg mape, avg, rmse)\n",
    "\n",
    "ALPHAS = [10_000, 5_000, 1_000, 500.0, 100.0, 50.0, 10.0, 5.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "for alpha in ALPHAS:\n",
    "    k = (alpha)\n",
    "    if k in tests:\n",
    "        continue\n",
    "\n",
    "    mlp_model = Ridge(alpha)\n",
    "    rmses, mapes, y_trues, y_preds = evaluate_cross_validation(mlp_model, all_data_test_train_splits)\n",
    "    avg_mape = sum(mapes) / len(mapes)\n",
    "    avg_rmse = sum(rmses) / len(rmses)\n",
    "    tests[k] = (avg_mape, avg_rmse)\n",
    "    \n",
    "    print(f\"(alpha={alpha}) => (MAPE={avg_mape}, RMSE={avg_rmse})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [{'alpha': k, 'mape': v[0], 'rmse': v[1]} for k,v in tests.items()]\n",
    "hp_df = pd.DataFrame(rows)\n",
    "hp_df[hp_df[\"rmse\"] == hp_df[\"rmse\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_best_models(Ridge(100), all_data_test_train_splits, \"Ridge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_random_range(min=2, max=64):\n",
    "    min_log = math.log(min, 2)\n",
    "    max_log = math.log(max, 2)\n",
    "\n",
    "    rand_log = min_log + (random.random() * (max_log - min_log))\n",
    "    rand = math.pow(2, rand_log)\n",
    "    return rand\n",
    "\n",
    "RANDOM_SAMPLES = 30\n",
    "tests = {} # (layer_1, layer_2, activation) => (avg mape, avg, rmse)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "for i in range(RANDOM_SAMPLES):\n",
    "    layer_1 = int(scaled_random_range(1, 128))\n",
    "    layer_2 = int(scaled_random_range(1, 128))\n",
    "    activation_func = choice([\"relu\", \"tanh\", \"logistic\"])\n",
    "\n",
    "    k = (layer_1, layer_2, activation_func)\n",
    "    if k in tests:\n",
    "        continue\n",
    "\n",
    "    mlp_model = MLPRegressor(hidden_layer_sizes=(layer_1, layer_2), activation=activation_func, early_stopping=True, max_iter=10_000)\n",
    "    rmses, mapes, y_trues, y_preds = evaluate_cross_validation(mlp_model, all_data_test_train_splits)\n",
    "    avg_mape = sum(mapes) / len(mapes)\n",
    "    avg_rmse = sum(rmses) / len(rmses)\n",
    "    tests[k] = (avg_mape, avg_rmse)\n",
    "    \n",
    "    print(f\"Sample {i} (layer_1={layer_1}, layer_2={layer_2}, activation={activation_func}) => (MAPE={avg_mape}, RMSE={avg_rmse})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [{'layer_1': k[0], 'layer_2': k[1], 'activation': k[2], 'mape': v[0], 'rmse': v[1]} for k,v in tests.items()]\n",
    "hp_df = pd.DataFrame(rows)\n",
    "hp_df[hp_df[\"rmse\"] == hp_df[\"rmse\"].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_best_models(MLPRegressor(hidden_layer_sizes=(15, 32), activation=\"logistic\", early_stopping=True, max_iter=10_000), all_data_test_train_splits, \"MLP\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
